---
marp: true
theme: default
paginate: true


---

### 301: ADAPTIVE LATTICE-AWARE IMAGE DEMOSAICKING USING GLOBAL AND LOCAL INFORMATION

#### Ji-Soo Kim, Keunsoo Ko, and Chang-Su Kim

#### School of Electrical Engineering, Korea University, Seoul, Korea jisookim@mcl.korea.ac.kr, ksko@mcl.korea.ac.kr, changsukim@korea.ac.kr

2020 IEEE International Conference on Image Processing (ICIP), 2020, pp. 483-487, doi: 10.1109/ICIP40778.2020.9190936.
h5-index: 52

Speaker: Guenet Ilan

---

<style>
div.twocols {
  margin-top: 35px;
  column-count: 2;
}
div.twocols p:first-child,
div.twocols h1:first-child,
div.twocols h2:first-child,
div.twocols ul:first-child,
div.twocols ul li:first-child,
div.twocols ul li p:first-child {
  margin-top: 0 !important;
}
div.twocols p.break {
  break-before: column;
  margin-top: 0;
}

</style>

<style>
img[alt~="center"] {
  display: block;
  margin: 0 auto;
}
</style>

<style>
div.caption {
  font-size: 20px;
  font-style: italic;
  display: block;
  margin: 0 auto;
}
</style>

### What is demosaicking?
<div class="twocols">

![width:500px height:200 center](https://i.imgur.com/eXIu04z.png)
<div class="caption">Color filter array (left) and full-color image (right)</div>

<p class="break"></p>

![center](https://i.imgur.com/y2K30lj.png)
<div class="caption">Color filter array interpolation</div>

</div>

* Color filter array (CFA). Only allow single intensity per pixel which result.
* 25% of red, 50% of green and 25% of blue.
* To render a full-color image, every missing values must be interpolated -> this process is called demosaicking.
* Collection of interpolation algorithms.

---

### CNN (**C**onvolutional **N**eural **N**etwork) based demosaicking

* New way for demosaicking with CNN. Outperform traditional algorithms **BUT** they do not consider lattice structures in CFAs systematically.

* **Solution**
  * **Adaptative lattice-aware Filter generator**: Determines effectively and dynamically the interpolation filters for each pixel.
  * **Local demosaicking**: Use the filter generated by the ALF generator to compute a locally demoisaicked image.
  * **Global refinement unit**: Exploit global image information to refine locally demosaicked images.

---

### ALF (**A**daptive **L**attice-aware **F**ilter) generation

**Goal:** determines effectively and dynamically the interpolation filters for each pixel. **Consider the lattice**.

* For each pixel compute the coefficients of three filters of size 5x5 to interpolate respectively the red, green and blue.
* Adaptive to the traits of the local area
* Use DenseNet neural network
* Train 3 generators for the 3 colors
* From $I^m$ (input mosaic image) generate $F_{x, y}^R,  F_{x, y}^G,  F_{x, y}^B\in\mathbb{R}^{5\times5}$

---

### Example of generated filters

![width:700px height:500px center](https://i.imgur.com/sAoNszX.png)
<div class="caption">Different possible layouts of generated filters for the red channel (left) and green channel (right). The blue channel behaves like the red channel</div>

---

### ALF generation (DenseNet)

* **Densely connected convolutional network** as backbone of the network
* Each layer produces feature maps
* Connect all layers directly with each other $x_l= H([x_0,x_1,...,x_{l-1}])$
* **Reduce** the number of parameters
* **Strengthen** features propragation

![center](https://i.imgur.com/5lBLxM0.png)
<div class="caption">Adaptive lattice-aware filter generator using a densely connected convultional network</div>

<style>
cite {
  font-size: 20px;
}
</style>

<cite>
G. Huang, Z. Liu, L. Van Der Maaten and K. Q. Weinberger, "Densely Connected Convolutional Networks," 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017, pp. 2261-2269, doi: 10.1109/CVPR.2017.243.
</cite>


---

### Local demosaicking

**Goal:** Use the filters generated by the ALF generator to compute a locally demoisaicked image.

* Use the **information in the neighborhood** of each pixel only
* Divide $I^m$ into 3 channels ($R^m, G^m, B^m$)
* For each pixel convolute a channel with its corresponding generated filter.$G^{dm}(x, y) = \sum_{i=-2}^2\sum_{j=-2}^2F_{x, y}^G(i, j)G^m(x+i, y+j)$
* $(R^{dm}, G^{dm}, B^{dm}) = I^{md}$ such that $I^{md}$ is the locally demosaicked image.

---

### GRU (**G**lobal **R**efinement **U**nit)

**Goal:** Exploit global information to refine locally demosaicked images efficiently.

* Based on the **residual dense network**.
* Better and quicker convergence
* Extract abundant local features
* Dilated convolutions to exploit global information more effectively

![center](https://i.imgur.com/ZyZQVkb.png)
<div class="caption">Example of an use-case of a residual dense network</div>

<cite>
Y. Zhang, Y. Tian, Y. Kong, B. Zhong and Y. Fu, "Residual Dense Network for Image Super-Resolution," 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2018, pp. 2472-2481, doi: 10.1109/CVPR.2018.00262.
</cite>

---

### Network training

* Minimize objective function given by $\mathcal{L} = \mathcal{L}_{local} + \mathcal{L}_{global}$ where:
    * $\mathcal{L}_{local} = \frac{1}{WH}\sum_{x=1}^{W}\sum_{y=1}^{H}\lVert I^{dm}(x, y) - \bar{I}(x, y) \rVert{_1}$
      *  Compare a locally demoisaicked image $I^{dm}$ with the ground truth $\bar{I}$
    * $\mathcal{L}_{global} = \frac{1}{WH}\sum_{x=1}^{W}\sum_{y=1}^{H}\lVert \mathcal{R}(x, y) - \mathcal{R}_{GRU}(x, y)\rVert{_1}$
      * Compare a defined residual image $\mathcal{R} = \bar{I} - I^{dm}$ with the predicted residual image $\mathcal{R}_{GRU}$.
    * The minimization of **$\mathcal{L}_{global}$ depends on $\mathcal{L}_{local}$**
* Adam Optimizer with a learning rate of $10^{-4}$, a batch size of 4 for 60 epochs

---


### Overall architecture

![center](https://i.imgur.com/4g0TxAa.png)
<div class="caption">Overall architecture of the proposed solution</div>

---
### Experiment results

* Flickr500 (500 images) dataset for training
* Kodak (12 images) and McMaster (18 images) dataset for evaluation
* **Peak signal-to-noise ratio** (PSNR) score: ratio between the maximum possible power of a signal and the power of corrupting noise (computing with a **Mean Square Error**) that affects the fidelity of its representation.
* Higher PSNR indicates that the reconstruction is of higher quality

---

### Results comparison
|  |      Kodak      |  McMaster |
|----------|:-------------:|------:|
| Menon et al. |39.19 | 32.27 |
| Zhang and Wu | 40.11 | 34.47 |
| Kiku et al. | 39.17 | 36.89 |
| Gharbi et al. | 41.20 | 39.50 |
| Tan et al. | 42.12 | 37.29 |
| Kokkinos and Lefkimmiatis | 41.50 | 39.70 |
||
| **Proposed** |**43.19** | **39.82** |

<cite>
Every reference given here can be found in the paper
</cite>

---

### Conclusion

* 3 steps:
  * **Filters generations** adapted the to pixel neighborhood
  * **Local demosaicking** by interpolating the input with the generated filters
  * **Refine** locally demoisaicked images by using a residual dense network
* To obtain a **globally demoisaicked full-color image**
* **State-of-the-art** demoisaicking technique (outperform others)

---

### Bibliography

- G. Huang, Z. Liu, L. Van Der Maaten and K. Q. Weinberger, "Densely Connected Convolutional Networks," 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017, pp. 2261-2269, doi: 10.1109/CVPR.2017.243.
- Y. Zhang, Y. Tian, Y. Kong, B. Zhong and Y. Fu, "Residual Dense Network for Image Super-Resolution," 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2018, pp. 2472-2481, doi: 10.1109/CVPR.2018.00262.
- D. Menon, S. Andriani, and G. Calvagno, "Demosaicing with directional filtering and a posteriori decision," IEEE Trans. Image Process., vol. 16, no. 1, pp. 132â€“141, 2007.
- F. Kokkinos and S. Lefkimmiatis, "Deep image demosaicking using a cascade of convolutional residual denoising networks," in ECCV, 2018.